{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b3e4c6-145b-4bbe-9e2f-aeab0891b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f84c0d5f-c584-4d1d-a380-e150fdc73681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def get_SDF(direction=['z', 'x', 'y']):\n",
    "    sdf = []\n",
    "    for d in direction:\n",
    "            sdf.append(nib.load(f'DF{d}.nii.gz').get_fdata())\n",
    "    sdf = np.stack(sdf, axis=-1)\n",
    "    nib.save(nib.Nifti1Image(df, np.eye(4)), 'DF.nii.gz')\n",
    "    return sdf\n",
    "\n",
    "def generate_grid(imgshape):\n",
    "    grid = np.mgrid[0:imgshape[0], 0:imgshape[1], 0:imgshape[2]].transpose(1, 2, 3, 0)[..., [2, 1, 0]]\n",
    "    grid = torch.from_numpy(grid).unsqueeze(0).float()\n",
    "    return grid\n",
    "    \n",
    "def transform(x, flow):\n",
    "    grid = generate_grid(flow.shape[1:])\n",
    "    grid = grid + flow\n",
    "    grid[0, :, :, :, 0] = (grid[0, :, :, :, 0] - ((grid.size()[3] - 1) / 2)) / (grid.size()[3] - 1) * 2\n",
    "    grid[0, :, :, :, 1] = (grid[0, :, :, :, 1] - ((grid.size()[2] - 1) / 2)) / (grid.size()[2] - 1) * 2\n",
    "    grid[0, :, :, :, 2] = (grid[0, :, :, :, 2] - ((grid.size()[1] - 1) / 2)) / (grid.size()[1] - 1) * 2\n",
    "    x = torch.nn.functional.grid_sample(x, grid, mode='bilinear', align_corners=True)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8ada6cff-a27e-4c1a-8adf-3165c3dc4ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------\n",
      "DRAMMS: Deformable image Registration via Attribute Matching and Mutual-Saliency weighting\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "Step 1:   Convert images to byte datatype...\n",
      "Step 2:   Match histograms if necessary...\n",
      "Step 3:   Affine registration of images by FSL's flirt tool (may take several minutes)...\n",
      "Step 4:   Skip preprocessing of the initial transformation as none was specified.\n",
      "Step 5a:  Generate multi-resolution images for the extraction of Gabor attributes...\n",
      "Step 5b:  Extract Gabor attributes for deformable registration...\n",
      "Step 6:   Deformably register images via attribute matching and mutual-saliency weighting (be patient, may take tens of minutes)...\n",
      "\n",
      "Deform3D -b0,0,0 -p -r3 -C0 -n5 -k10 -s0.50 -m1 -f0 -M2 -w1 -g.35555555555555555554 -e0 -F0 -S0 -u2 -a/tmp/dramms-WXiDHI/features/B_level1_mask.nii.gz /tmp/dramms-WXiDHI/features/A2B_affine_level1.nii.gz /tmp/dramms-WXiDHI/features/B_level1.nii.gz /tmp/dramms-WXiDHI/features/GaborUsed_ A2B.nii.gz DField.nii.gz\n",
      "\n",
      "Step 7:   Combine the affine and deformable transformations into an unified deformation...\n",
      "Step 8:   Warp the input image and write output files...\n",
      "\n",
      "The registered image has been saved to file src2trg.nii.gz, deformation to file def_src2trg.nii.gz\n",
      "\n",
      "\n",
      "Total time used: 27.46 minutes.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('./bin/dramms --source brain.nii.gz --target MNI152SymNonLinear.nii.gz --outimg src2trg.nii.gz --outdef def_src2trg.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a07064b3-6e29-412e-beec-06c9b6b74662",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = torch.from_numpy(get_SDF()).unsqueeze(dim=0).float()\n",
    "source = torch.from_numpy(nib.load('brain.nii.gz').get_fdata()).unsqueeze(dim=0).unsqueeze(dim=0).float()\n",
    "target = torch.from_numpy(nib.load('MNI152SymNonLinear.nii.gz').get_fdata()).unsqueeze(dim=0).unsqueeze(dim=0).float()\n",
    "s2t = transform(source, sdf).type(torch.int16).squeeze()\n",
    "nib.save(nib.Nifti1Image(s2t.numpy(), np.eye(4)), f'S2T.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158e3e1c-ce53-4c65-b0b6-7ad6e0e064c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
